TF 2.0 is a C++ engine for mathematics

Flattens an n-tensor into a 1-tensor

more layers == more layers of features
softmax means give me a probability distribution based on the input data
cross entropy compares two probability distributions

pip install tensorflow-gpu==2.0.0-beta1
import tensorflow as tf
tf.__version__

flow comes from the fact that a dataflow graph is built from your program
in c++, compiles it, and then executes that.

Roughly, TF2 works like numpy, replacing ndarrays with tensors that can be
accelerated on a GPU, and we can backprop through it.
In TF1, you would actually build your dataflow graph and then do:
with tf.Session() as sess:
    print(sess.run(x))
By default in TF2 your code will run in the standard mode, but you can do
@tf.function to make it go real fast (recursively sends all code inside of
it to the tensor back end to be compiled)

Going big: running on multiple GPUs
strategy = tf.distribute.MirroredStrategy()
with strategy.scope():
    model = ..
Here the bottleneck is getting your input data off disk and into memory
In TF, the way you can get disk to GPUs quickly is using tf.data (it is not
easy to learn but can remove the latency that comes from disk IOs)

Previously, Keras was effectively an API without an implementation, and could sit on
top of any tensor backend.
from tensorflow.keras import layers
from keras import layers

Keras offers a few APIs
1. Sequential (layered)
2. Functional API (DAG) -- useful for skip connections and residual networks
3. Subclassing API (very similar to chainer and PyTorch) where a model is
   defined by extending a class
    -- In the constructor you define your layers
    -- In the call method, you define the forward pass

All models can be fit by
1. model.fit
2.
with tf.GradientTape() as tape:
    pass
grads = tape.gradient(loss_value, model.trainable_variables)

here, all computations in the with block are recorded on a graph (tape) and then run backwards
to get the gradients

Note: Rachel/Josh optimizer

When you call the data, you send it through the forward pass.
Next, you take a loss function (error) as a function of your other variables
which allows you to quantify how good or bad the parameters are. Deep networks
are not convex, but we can hope to find some sort of a minima. In calculus, the
gradient is the direction of maximal increase

Numeric gradients: make the variable slightly bigger, recompute your loss
                   make the variable slightly smaller, recompute your loss
                   determine which way made your loss go down.
                   unfortunately this requires two forward passes through your data
Analytic gradients: if you are smart with calculus theorems, you can do it in a way
                    that is linear with the time of nodes in the computational graph

batch size: smaller batches take less time (SGD)
            larger batches take more time but are more accurate updates (batch)
            in practice: mini-batch

great image at 46:52 that is slowly built up to

sigmoid forces a number to [0, 1] but has nasty properties with gradient descent since
it flattens near the extremes leading to very slow training.

relu makes your models train much faster

